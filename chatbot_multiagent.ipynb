{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load env ------------------------------------------------------------------------\n",
    "import os\n",
    "import utils\n",
    "\n",
    "utils.load_env()\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = \"false\"\n",
    "\n",
    "\n",
    "# debug ------------------------------------------------------------------\n",
    "from langchain.globals import set_debug, set_verbose\n",
    "set_verbose(True)\n",
    "set_debug(False)\n",
    "\n",
    "from langchain_core.messages import (\n",
    "    AIMessage, \n",
    "    HumanMessage,\n",
    "    ToolMessage\n",
    ")\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from agents import(\n",
    "    AgentState,\n",
    "    agents_metadata,\n",
    "    agent_names\n",
    ")\n",
    "from tools import get_tools_output, all_tools\n",
    "from chat_history import save_chat_history, load_chat_history\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "## Define Tool Node\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from typing import Literal\n",
    "\n",
    "tool_node = ToolNode(all_tools)\n",
    "\n",
    "def router(state) -> Literal[\"call_tool\", \"continue\", \"supervisor\", \"creative_communication_agent\", \"crm_agent\", \"__end__\"]:\n",
    "    # This is the router\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    if \"FINALANSWER\" in last_message.content:\n",
    "        return \"__end__\"\n",
    "    if \"supervisor\" in last_message.content:\n",
    "        return \"supervisor\"\n",
    "    if \"creative_communication_agent\" in last_message.content:\n",
    "        return \"creative_communication_agent\"\n",
    "    if \"crm_agent\" in last_message.content:\n",
    "        return \"crm_agent\"\n",
    "    if last_message.tool_calls:\n",
    "        # The previous agent is invoking a tool\n",
    "        return \"call_tool\"\n",
    "    else:\n",
    "        return \"continue\"\n",
    "\n",
    "\n",
    "## Workflow Graph ------------------------------------------------------------------------\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# add agent nodes\n",
    "for name, value in agents_metadata.items():\n",
    "    workflow.add_node(name, value['node'])\n",
    "    \n",
    "workflow.add_node(\"call_tool\", tool_node)\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"supervisor\",\n",
    "    router,\n",
    "    {\n",
    "        \"crm_agent\":\"crm_agent\",\n",
    "        \"creative_communication_agent\":\"creative_communication_agent\",\n",
    "        \"call_tool\": \"call_tool\",\n",
    "        \"__end__\": END,\n",
    "        \"continue\": END, \n",
    "        }\n",
    ")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"creative_communication_agent\",\n",
    "    router,\n",
    "    {\n",
    "        \"call_tool\": \"call_tool\",\n",
    "        \"continue\": \"supervisor\", \n",
    "        }\n",
    ")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"crm_agent\",\n",
    "    router,\n",
    "    {\n",
    "        \"call_tool\": \"call_tool\",\n",
    "        \"continue\": \"supervisor\", \n",
    "        }\n",
    ")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"call_tool\",\n",
    "    # Each agent node updates the 'sender' field\n",
    "    # the tool calling node does not, meaning\n",
    "    # this edge will route back to the original agent\n",
    "    # who invoked the tool\n",
    "    lambda x: x[\"sender\"],\n",
    "    {name:name for name in agent_names},\n",
    ")\n",
    "\n",
    "workflow.add_edge(START, \"supervisor\")\n",
    "graph = workflow.compile()\n",
    "\n",
    "def submitUserMessage(\n",
    "    user_input:str, \n",
    "    user_id:str=\"test\", \n",
    "    keep_chat_history:bool=False, \n",
    "    return_reference:bool=False, \n",
    "    verbose:bool=False,\n",
    "    recursion_limit:int=20\n",
    "    ) -> str:\n",
    "    \n",
    "    os.environ['CURRENT_USER_ID'] = user_id\n",
    "    \n",
    "    chat_history = load_chat_history(user_id=user_id) if keep_chat_history else []\n",
    "    chat_history = chat_history[-20:]\n",
    "    \n",
    "    # memory only keep chat history only along agents.\n",
    "    internal_level_memory = MemorySaver()\n",
    "    graph = workflow.compile(checkpointer=internal_level_memory)\n",
    "\n",
    "    events = graph.stream(\n",
    "        {\n",
    "            \"messages\": [\n",
    "                HumanMessage(\n",
    "                    user_input\n",
    "                )\n",
    "            ],\n",
    "            \"chat_history\": chat_history\n",
    "        },\n",
    "        # Maximum number of steps to take in the graph\n",
    "        {\"recursion_limit\": recursion_limit, \"thread_id\":\"a\"},\n",
    "    )\n",
    "    \n",
    "    if not verbose:\n",
    "        events = [e for e in events]\n",
    "        response = list(events[-1].values())[0]\n",
    "    else:\n",
    "        for e in events:\n",
    "            a = list(e.items())[0]\n",
    "            a[1]['messages'][0].pretty_print()\n",
    "        \n",
    "        response = a[1]\n",
    "    \n",
    "    response = response[\"messages\"][0].content\n",
    "    response = utils.format_bot_response(response, markdown=True)\n",
    "    \n",
    "    if keep_chat_history:\n",
    "        save_chat_history(bot_message=response, human_message=user_input, user_id=user_id)\n",
    "    \n",
    "    if return_reference:\n",
    "        return response, get_tools_output()\n",
    "    else:\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import Image, display\n",
    "\n",
    "# try:\n",
    "#     display(Image(graph.get_graph(xray=True).draw_mermaid_png()))\n",
    "# except Exception:\n",
    "#     # This requires some extra dependencies and is optional\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: supervisor\n",
      "\n",
      "ฉันจะส่งข้อมูลนี้ไปยัง CRM Agent เพื่อดึงข้อมูลลูกค้าเพิ่มเติมเกี่ยวกับความชอบของคุณค่ะ\n",
      "\n",
      "ส่งข้อความไปยัง CRM Agent:\n",
      "\n",
      "\"สวัสดีค่ะ CRM Agent, \n",
      "ลูกค้ารายนี้ได้แจ้งว่าพวกเขาชอบ iPhone กรุณาช่วยดึงข้อมูลเพิ่มเติมเกี่ยวกับลูกค้ารายนี้เพื่อให้เราสามารถให้บริการที่ตรงตามความต้องการของพวกเขาได้ค่ะ ขอบคุณค่ะ!\"\n"
     ]
    }
   ],
   "source": [
    "# import utils\n",
    "result = submitUserMessage(\"ฉันชอบ iphone\", keep_chat_history=True, return_reference=True, verbose=True)\n",
    "utils.notify(sound_effect=\"purr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: supervisor\n",
      "\n",
      "ตอนนี้ฉันจะส่งข้อมูลนี้ไปยัง Creative Communication Agent เพื่อให้พวกเขาช่วยในการแนะนำสินค้าที่เกี่ยวข้องกับ iPhone ค่ะ\n",
      "\n",
      "ส่งข้อความไปยัง Creative Communication Agent:\n",
      "\n",
      "\"สวัสดีค่ะ Creative Communication Agent,\n",
      "ลูกค้ารายนี้ได้แจ้งว่าพวกเขาชอบ iPhone และขอให้เราช่วยแนะนำสินค้าที่เกี่ยวข้อง กรุณาช่วยจัดทำคำแนะนำสินค้าที่เหมาะสมกับความชอบของลูกค้าได้ไหมคะ ขอบคุณค่ะ!\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('ตอนนี้ฉันจะส่งข้อมูลนี้ไปยัง Creative Communication Agent เพื่อให้พวกเขาช่วยในการแนะนำสินค้าที่เกี่ยวข้องกับ iPhone ค่ะ\\n\\nส่งข้อความไปยัง Creative Communication Agent:\\n\\n\"สวัสดีค่ะ Creative Communication Agent,\\nลูกค้ารายนี้ได้แจ้งว่าพวกเขาชอบ iPhone และขอให้เราช่วยแนะนำสินค้าที่เกี่ยวข้อง กรุณาช่วยจัดทำคำแนะนำสินค้าที่เหมาะสมกับความชอบของลูกค้าได้ไหมคะ ขอบคุณค่ะ!\"',\n",
       " '')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submitUserMessage(\"ช่่วยแนะนำสินค้าหน่่อย\", keep_chat_history=True, return_reference=True, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
